"""
LLM Provider Factory
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Change LLM_PROVIDER in .env to swap:
  gemini    -> Google Gemini (best Bengali, cheapest)
  openai    -> OpenAI GPT models
  anthropic -> Anthropic Claude models
  groq      -> Groq ultra-fast inference
  deepseek  -> DeepSeek (excellent Bengali, very cheap)
  custom    -> Any OpenAI-compatible API endpoint
              (Ollama, vLLM, LM Studio, Together AI, Fireworks, etc.)
"""

from __future__ import annotations

import logging
from livekit.agents import llm as llm_module

# All plugin imports at top level (required by LiveKit)
from livekit.plugins import google as google_plugin
from livekit.plugins import openai as openai_plugin

try:
    from livekit.plugins import anthropic as anthropic_plugin
except ImportError:
    anthropic_plugin = None

from config import config

logger = logging.getLogger("voice-agent.llm")


def get_llm() -> llm_module.LLM:
    """Return the configured LLM instance based on .env settings."""

    provider = config.llm_provider.lower()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Google Gemini
    # Best Bengali understanding, cheapest
    # Requires: GOOGLE_API_KEY
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if provider == "gemini":
        logger.info(f"ðŸ§  LLM: Google Gemini ({config.gemini_model})")
        return google_plugin.LLM(
            model=config.gemini_model,
            api_key=config.google_api_key or None,
        )

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # OpenAI GPT
    # Strong Bengali, reliable
    # Requires: OPENAI_API_KEY
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif provider == "openai":
        logger.info(f"ðŸ§  LLM: OpenAI ({config.openai_model})")
        return openai_plugin.LLM(
            model=config.openai_model,
            api_key=config.openai_api_key or None,
        )

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Anthropic Claude
    # Strong Bengali, great reasoning
    # Requires: ANTHROPIC_API_KEY
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif provider == "anthropic":
        if anthropic_plugin is None:
            raise ImportError(
                "Anthropic LLM requires livekit-plugins-anthropic. "
                "Install: pip install livekit-plugins-anthropic"
            )
        logger.info(f"ðŸ§  LLM: Anthropic Claude ({config.anthropic_model})")
        return anthropic_plugin.LLM(
            model=config.anthropic_model,
            api_key=config.anthropic_api_key or None,
        )

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Groq (ultra-fast inference)
    # OpenAI-compatible API, free tier
    # Requires: GROQ_API_KEY
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif provider == "groq":
        logger.info(f"ðŸ§  LLM: Groq ({config.groq_model})")
        return openai_plugin.LLM(
            model=config.groq_model,
            api_key=config.groq_api_key or None,
            base_url="https://api.groq.com/openai/v1",
        )

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # DeepSeek
    # Excellent Bengali, very cheap, OpenAI-compatible
    # Requires: DEEPSEEK_API_KEY
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif provider == "deepseek":
        logger.info(f"ðŸ§  LLM: DeepSeek ({config.deepseek_model})")
        if not config.deepseek_api_key:
            raise ValueError(
                "DeepSeek requires DEEPSEEK_API_KEY in .env. "
                "Get one at https://platform.deepseek.com/"
            )
        return openai_plugin.LLM(
            model=config.deepseek_model,
            api_key=config.deepseek_api_key,
            base_url=config.deepseek_base_url,
        )

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Custom OpenAI-compatible endpoint
    # Works with: Ollama, vLLM, LM Studio,
    # Together AI, Fireworks, OpenRouter, etc.
    #
    # Set in .env:
    #   CUSTOM_LLM_URL=http://localhost:11434/v1   (Ollama)
    #   CUSTOM_LLM_MODEL=llama3.1
    #   CUSTOM_LLM_API_KEY=not-needed
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif provider == "custom":
        logger.info(
            f"ðŸ§  LLM: Custom endpoint ({config.custom_llm_url}, "
            f"model={config.custom_llm_model})"
        )
        return openai_plugin.LLM(
            model=config.custom_llm_model,
            api_key=config.custom_llm_api_key,
            base_url=config.custom_llm_url,
        )

    else:
        raise ValueError(
            f"Unknown LLM_PROVIDER: '{provider}'. "
            f"Valid options: gemini, openai, anthropic, groq, deepseek, custom"
        )
